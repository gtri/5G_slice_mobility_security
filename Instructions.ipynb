{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRO \n",
    "This notebook details 5G scenario preparation, data collection, processing, and offline AI model training. \n",
    "\n",
    "For the preparation and data collection sections it is assumed that readers will already have working 5G infrastructure. \n",
    "\n",
    "Infrastructure includes:\n",
    "- A working Open5GS core with Prometheus enabled \n",
    "- 6 Open5GS UPFs (if you want to replicate our scenario exactly)\n",
    "- An Amarisoft gnb and ue sim \n",
    "- A deployment of ONAP v13.0.0\n",
    "- VESPA for Prometheus - VES event conversion \n",
    "\n",
    "![Full testbed](./artifacts/experiment_figures/Full-Core.png)\n",
    "\n",
    "In the above image you can see the interfaces connecting different portions of the testbed. The Amarisoft callbox hosts the eNB which must be registered with the Open5GS core network. Each of the UPFs in the core network must be routed to the control plane in the SMF configuration. Open5GS core metrics are supplied to the ONAP message router through VESPA which sends Prometheus data to the ONAP VES-collector. \n",
    "\n",
    "# Setup \n",
    "\n",
    "## Open5GS \n",
    "The artifacts of our deployment are included in the Open5GS-Artifacts directory. These artifacts can be deployed in your cluster to set up the SMF, AMF, and NSSF in our configuration. The SMF and AMF HPA scaling rules are also included. \n",
    "\n",
    "### UPF Modifications \n",
    "The Open5GS deployment needs to be modified to support multiple slices. For our core network we deployed each UPF on a separate VM and specified routing rules to enable communication with the core network. The outline of our routing rules:\n",
    "\n",
    "```\n",
    "sudo ip tuntap add name ogstun mode tun\n",
    "sudo ip addr add 10.46.0.1/16 dev ogstun    # 10.46.0.1/16 is the subnet used for upf sessions \n",
    "sudo ip link set ogstun up\n",
    "sudo iptables -t nat -A POSTROUTING -s 10.46.0.0/16 ! -o ogstun -j MASQUERADE\n",
    "./install/bin/open5gs-upfd\n",
    "sudo ip route add UPF_IP via CORE_IP\n",
    "```\n",
    "\n",
    "Additionally, we needed to edit the Open5GS code to enable counters which had been previously disabled due to performance issues. See the following dif:\n",
    "```\n",
    "diff --git a/src/upf/gtp-path.c b/src/upf/gtp-path.c\n",
    "index d2fef084d..1676f3bce 100644\n",
    "--- a/src/upf/gtp-path.c\n",
    "+++ b/src/upf/gtp-path.c\n",
    "@@ -223,7 +223,7 @@ static void _gtpv1_tun_recv_common_cb(\n",
    "      * It should not be used on the UPF/SGW-U data plane\n",
    "      * until this issue is resolved.\n",
    "      */\n",
    "-#if 0\n",
    "+#if 1\n",
    "     upf_metrics_inst_global_inc(UPF_METR_GLOB_CTR_GTP_OUTDATAPKTN3UPF);\n",
    "     upf_metrics_inst_by_qfi_add(pdr->qer->qfi,\n",
    "         UPF_METR_CTR_GTP_OUTDATAVOLUMEQOSLEVELN3UPF, recvbuf->len);\n",
    "@@ -390,7 +390,7 @@ static void _gtpv1_u_recv_cb(short when, ogs_socket_t fd, void *data)\n",
    "          * It should not be used on the UPF/SGW-U data plane\n",
    "          * until this issue is resolved.\n",
    "          */\n",
    "-#if 0\n",
    "+#if 1\n",
    "         upf_metrics_inst_global_inc(UPF_METR_GLOB_CTR_GTP_INDATAPKTN3UPF);\n",
    "         upf_metrics_inst_by_qfi_add(header_desc.qos_flow_identifier,\n",
    "                 UPF_METR_CTR_GTP_INDATAVOLUMEQOSLEVELN3UPF, pkbuf->len);\n",
    "```\n",
    "\n",
    "\n",
    "### UE Definitions on Open5GS \n",
    "The `reset_database.sh` script can be used to add the same UE configurations to the Open5GS dbctl. You need to provide it with the name of your populate pod. It is *extremely* unoptimized and slow because it uses the open5gs-dbctl commands to add UE entries rather than going straight to mongodb. \n",
    "\n",
    "## VESPA\n",
    "See the VESPA github to setup VESPA https://github.com/nokia/ONAP-VESPA. Our ves-agent.yml configuration is included in the Open5GS-Artifacts directory. **Modify it to reference your IP addresses** if you want to use the same VES events as us. \n",
    "\n",
    "Configuring VESPA:\n",
    "```\n",
    "sudo cp ves-agent.yml /etc/ves-agent/\n",
    "```\n",
    "\n",
    "Once the VES-collector is running on ONAP, VSEPA can be used to send Prometheus data collected from the Open5GS core to the ONAP VES-collector. VESPA is activated from the ves-agent directory in the VESPA project. \n",
    "```\n",
    "./ves-agent\n",
    "```\n",
    "\n",
    "The VES agent will send POSTs to the address specified in ves-agent.ml and if successful will return a 200 response. \n",
    "\n",
    "## Amarisoft \n",
    "The `Amarisoft` directory contains the scenarios we used for data collection. These scenarios can be loaded into Amarisoft by replacing the default `ue.cfg` file and running `systemctl restart lte`. \n",
    "\n",
    "You can make your own scenarios by either manually scripting \"sim_events\" similar to `Amarisoft/ue-list.json` or by using the Amarisoft UE SIM BOX GUI. \n",
    "\n",
    "DSM attack scenarios can be created from benign scenarios by taking the `ue-list.json` file you wish to modify and using `manual_dsm.py`. This python file assumes that you used the same UE ids and configuration as our deployment and **will not** work on arbitrary scenarios. \n",
    "\n",
    "Amarisoft uses collectd to scrape UE metrics from the callbox api. \n",
    "1. Install collectd on the Amarisoft UE SIM BOX VM\n",
    "2. Add `Amarisoft/Amarisoft UE data collection/collectd.conf` to `/etc/collectd` \n",
    "3. Add `Amarisoft/Amarisoft UE data collection/types.db` to `/etc/collectd/plugins/`\n",
    "4. Add `Amarisoft/Amarisoft UE data collection/enb_stats.py` to `/etc/collectd/plugins`\n",
    "5. Add `Amarisoft/Amarisoft UE data collection/enb_utils.py` to `/etc/collectd/plugins`\n",
    "6. Add `Amarisoft/Amarisoft UE data collection/enb_list.cfg` to `/etc/collectd/plugins/`\n",
    "\n",
    "# Data Collection \n",
    "1. Start the scenario from Amarisoft using `systemctl restart lte`\n",
    "\n",
    "    ## Open5GS \n",
    "    1. Activate the VES-Agent using `./ves-agent` wherever VESPA is located \n",
    "    2. Run `consumer.py` to begin collecting a VES events from the ONAP message router in JSON format\n",
    "\n",
    "    ## Amarisoft \n",
    "    1. Start the collectd plugin using `systemctl start collectd` \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: THIS CELL IS FOR DEMONSTRATION PURPOSES ONLY AND WILL THROW A TIMEOUT ERROR IF CANNOT CONNECT TO THE CORE NETWORK\n",
    "\n",
    "from consumer import *\n",
    "\n",
    "onap_ip = '127.0.0.1'\n",
    "message_router_port = '1234'\n",
    "scenario_duration = 60 # Given in seconds \n",
    "polling_interval = 15 # Given in seconds. Is determined by the configuration of Prometheus on the core network \n",
    "save_file = 'raw_data/core-ves-data.json'\n",
    "\n",
    "ves_consumer_main(onap_ip, message_router_port, scenario_duration, polling_interval, save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing \n",
    "These are the metrics we collected for our AI model:\n",
    "## Open5GS - Prometheus -> VESPA -> VES-Collector \n",
    "- Number of UE RAN connections \n",
    "- Number of AMF sessions per slice\n",
    "- Number of PDU creation requests per slice\n",
    "- Number of successful PDU session creations per slice \n",
    "- Number of N4 interface session establishment requests (between SMF and UPF) per slice\n",
    "- Number of successful N4 establishments per slice \n",
    "- Number of failed N4 establishments per slice \n",
    "- CPU resources requested per VNF \n",
    "- UE registration initiaions with the AMF\n",
    "- Successful UE registrations with the AMF\n",
    "- UPF uplink packet count per slice \n",
    "- UPF downlink packet count per slice \n",
    "- Number of SMF sessions per slice \n",
    "- Number of UEs active on the Open5GS core network \n",
    "- Container CPU use (CPU seconds)\n",
    "- AMF registered UE subscribers per slice \n",
    "- Number of PCF association requests per slice \n",
    "- Number of PCF sessions per slice \n",
    "\n",
    "## Amarisoft UE data (Collected for each UE)\n",
    "- Number of PDU sessions with each slice \n",
    "- Downlink rx \n",
    "- Downlink retransmissions \n",
    "- Downlink errors\n",
    "- Uplink tx\n",
    "- Uplink retransmissions\n",
    "- Uplink datarate\n",
    "- Downlink datarate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NRves2csv handles ves-csv conversion and processing UE data into a single csv \n",
    "from NRves2csv import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the paths to raw data and where you want to save it \n",
    "\n",
    "# Core data comes from a json file that lists all the VES events files to pull data from. \n",
    "# The json file specifies which scenarios are malicious and which slice is under attack\n",
    "core_data = Path('raw_data/core-data/ves_files_list.json') \n",
    "\n",
    "# UE data comes from a directory that has a sub-directory for each UE \n",
    "bengin_ue_dir = Path('raw_data/ue-data/ue-benign-samples')\n",
    "malicious_ue_dir = Path('raw_data/ue-data/ue-malicious-samples')\n",
    "\n",
    "# Define the save files \n",
    "save_file_core = Path('data/core-dataset.csv')\n",
    "save_file_slice = Path('data/slice-dataset.csv')\n",
    "save_file_ue = Path('data/ue-dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the raw core data into dataframes \n",
    "\n",
    "# Core Dataframe\n",
    "core_data = json.loads(core_data.read_text(encoding=\"UTF-8\"))\n",
    "ves_files = list(core_data.keys())\n",
    "mal_ids = [list(targets.values())[0] for targets in core_data.values()]\n",
    "target_slice_sds = [list(targets.values())[1] for targets in core_data.values()]\n",
    "core_frames = [ves2csv(Path(path), mal_id) for path, mal_id in zip(ves_files, mal_ids)]\n",
    "# Combined and save core data to csv\n",
    "core_df = combine_csv(core_frames, save_file_core)\n",
    "\n",
    "# Slice Dataframe \n",
    "# Specify the SST-SD of each slice as well as the IP address of the UPF VM \n",
    "# These labels are deployment specific and originate from the Prometheus -> VESPA -> ONAP data pipeline \n",
    "slice_labels = [('1-111111','10.1.0.138:9090'), \n",
    "                ('1-222222','10.1.0.201:9090'), \n",
    "                ('2-333333','10.1.0.228:9090'), \n",
    "                ('2-444444','10.1.0.33:9090'), \n",
    "                ('3-555555','10.1.0.76:9090'), \n",
    "                ('3-666666','10.1.0.232:9090')]\n",
    "# Split the core data by slice \n",
    "slice_frames = [split_slices(core_frame, slice_labels, target_slice_sd) for core_frame, target_slice_sd in zip(core_frames, target_slice_sds)]\n",
    "# Combine slice specific data frames and save to csv\n",
    "slice_df = combine_csv(slice_frames, save_file_slice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the raw UE data into dataframes \n",
    "\n",
    "# Specify data filters for UE data. EX: ['09-24'] will only include data from files with '09-24' in the title \n",
    "# benign_data_filter = ['09-24'] \n",
    "# malicious_data_filter = ['09-24']\n",
    "benign_data_filter = None \n",
    "malicious_data_filter = None\n",
    "\n",
    "# Load the list of malicious UE IMSIs: \n",
    "mal_ue_file = Path('artifacts/malicious_ues.json')\n",
    "mal_ue_info = json.loads(mal_ue_file.read_text(encoding=\"UTF-8\"))\n",
    "mal_ue_imsis = mal_ue_info['mal_ue_imsis']\n",
    "\n",
    "# UE Dataframes\n",
    "benign_ue_df = make_ue_df(bengin_ue_dir, benign_data_filter)\n",
    "malicious_ue_df = make_ue_df(malicious_ue_dir, malicious_data_filter, mal_ue_list = mal_ue_imsis, malicious = True)\n",
    "\n",
    "# Combine benign/malicious data and save to csv\n",
    "full_ue_df = combine_csv([benign_ue_df, malicious_ue_df], saveFile=save_file_ue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Datasets + Model \n",
    "Now that the raw data from the Open5GS core network and Amarisoft UEs has been processed into csv files we can create torch datasets and train AI models. \n",
    "\n",
    "TLDR:\n",
    "- Min-Max Scale\n",
    "- Sequences of (24) samples [[sampl1], [sample2], ... [sample24]]\n",
    "- Batched inputs to the torch model (batch size 100) during training \n",
    "- Batch size of 1 during testing \n",
    "    - Must be done to plot reconstruction loss of individual samples \n",
    "\n",
    "![Anomaly Detection Framework](./artifacts/experiment_figures/Anomaly-Detector.png)\n",
    "\n",
    "\n",
    "## Model Inputs \n",
    "We used 1D-CNN based autoencoders to capture the time dependency of the DSM attack. Each AI model takes a sequence of samples as an input. We used 24 samples per sequence to capture ~2min of data (at a sample rate of 5s) per inference made by the model. This sequence length was chosen in accordance with our DSM attack parameters which repeated at a frequency of ~2min. Each scenario we ran was 30min long. \n",
    "\n",
    "## Preprocessing \n",
    "### Scaling \n",
    "First, the UE and Core metrics have a wide scale (datarate could be in the thousands vs. # of PDU sessions which will be in the single digits) that needs to be standardized. We apply a Min-Max scaler to each feature so that larger features are not weighted more heavily. \n",
    "\n",
    "### Time-Series Sequences \n",
    "Sequences of 24 samples (can be modified by changing frame_size) are created by iterating through dataframes loaded from the processed csv files. Sequences of samples are created by walking through the csv file sample-by-sample and constructing a list of 24 samples. This means that each sample can contribute to multiple sequences. The list of samples is then cast to a float32 tensor using torch.stack(sample_frame).to(torch.float32). The first samples timestamp is set as the starting point and if the last sample in the expected sequence has a vastly different timestamp from what is expected the sequence is discarded. This prevents the data from different UEs, slices, or experiments from being merged together.  \n",
    "\n",
    "#### Example time series: \n",
    "- Time series 1: [[sample1], [sample2], [sample3], ... [sample24]] \n",
    "- Time series 2: [[sample2], [sample3], [sample4], ... [sample25]]\n",
    "\n",
    "## Training \n",
    "During model training the Autoencoder expects to only see benign data. This way, the autoencoder can be used to identify OOD data by looking at the reconstuction loss of samples. Malicious data should have a higher reconstruction loss because the Autoencoder has not seen similar data before. \n",
    "\n",
    "## Testing \n",
    "Benign and malicious data is included in the test set. The batch size **MUST BE SET TO 1** for the test loop in order to plot reconstruction loss. Batch size 1 is inconvenient for lots of data, but allows us to plot the reconstruction loss of every individual sample passed to the model. If we did a larger batch size the reconstruction loss would be calculated as the average over a set of samples and may lump benign and malicious data together.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slice Attack Dataset Creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NRTimeSeriesML import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup \n",
    "device = torch_setup()\n",
    "\n",
    "# Set the frame size for the DSM detection dataset \n",
    "# Data was collected at 5s intervals and the DSM attack we applied looped at ~2min intervals\n",
    "# We selected a frame size of 24 to capture the full DSM loop: 24 (samples) * 5 (seconds / sample)  = 120 seconds \n",
    "frame_size = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the slice data into a dataframe \n",
    "slice_df = pd.read_csv('data/slice-dataset.csv')\n",
    "\n",
    "# Split the dataframe into benign/malicious \n",
    "benign_slice = slice_df.loc[slice_df['label'] == 0]\n",
    "malicious_slice = slice_df.loc[slice_df['label'] == 1]\n",
    "\n",
    "# Setup a the data transformation - MinMaxScaler because the 5G data has large difference in scale across features \n",
    "transform_pipeline = Pipeline([('scaler', preprocessing.MinMaxScaler())])\n",
    "\n",
    "# Create the time-aware dataset (dataset id is used to shape features correctly 0: core dataset 1: slice dataset 2: ue dataset)\n",
    "slice_benign_dataset = NRTimeDataset(df=benign_slice, frame_length = frame_size, transform=transform_pipeline, dataset_id=1, fit=True)\n",
    "slice_mal_dataset = NRTimeDataset(df=malicious_slice, frame_length = frame_size, transform=transform_pipeline, dataset_id=1, fit=True)\n",
    "\n",
    "# Save the benign fit slice transformation for live data inference in the future \n",
    "pickle.dump(slice_benign_dataset.transform, open('artifacts/slice_transform.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split benign data \n",
    "slice_benign_split = torch.utils.data.random_split(slice_benign_dataset, [0.6,0.2,0.2])\n",
    "slice_train_dataset, slice_val_dataset, slice_test_dataset = slice_benign_split\n",
    "\n",
    "# All malicious data goes into the test set - The autoencoder is trained on BENIGN DATA ONLY! \n",
    "slice_test_dataset = slice_mal_dataset + slice_test_dataset\n",
    "\n",
    "# Create data loaders \n",
    "slice_train_dataloader = DataLoader(slice_train_dataset, batch_size=100, shuffle=True)\n",
    "slice_test_dataloader = DataLoader(slice_test_dataset, batch_size=1, shuffle=False) # Batch size 1 to track reconstruction loss of every sample "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slice Attack Detection Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN filter sizes for the autoencoder encoder and decoder \n",
    "filter_sizes = [8, 4]\n",
    "\n",
    "# Model definition - slice\n",
    "CNNautoencoder_slice = ConvAutoencoder(n_features = slice_benign_dataset.samples.size()[1], filter_sizes=filter_sizes)\n",
    "CNNautoencoder_slice.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Lightning model instantiation - Information about training will be output to the lightning_logs dir\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "NR_Autoencoder_slice = LitTimeAutoencoder(CNNautoencoder_slice, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and save the model \n",
    "# Autoencoder training \n",
    "trainer_slice = L.Trainer(limit_train_batches=100, max_epochs=100, callbacks=[AutoencoderReconstructionLoss()])\n",
    "trainer_slice.fit(model=NR_Autoencoder_slice, train_dataloaders=slice_train_dataloader) # Model is the lightning module here \n",
    "# Save the slice state_dict\n",
    "torch.save(CNNautoencoder_slice.state_dict(), 'artifacts/slice_state_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the reconstruction loss on test samples \n",
    "trainer_slice.test(NR_Autoencoder_slice, dataloaders=slice_test_dataloader)\n",
    "plot_reconsctruction_loss(NR_Autoencoder_slice.reconstruction_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UE Dataset Creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the UE data into a dataframe \n",
    "ue_df = pd.read_csv('data/ue-dataset.csv')\n",
    "\n",
    "# Split into bengin/malicious samples \n",
    "benign_ue = ue_df.loc[ue_df['label'] == 0]\n",
    "malicious_ue = ue_df.loc[ue_df['label'] == 1]\n",
    "\n",
    "# Create data transform + time series datasets \n",
    "transform_pipeline = Pipeline([('normalizer', preprocessing.Normalizer()), ('scaler', preprocessing.MinMaxScaler())])\n",
    "ue_benign_dataset = NRTimeDataset(df=benign_ue, frame_length = frame_size, transform=transform_pipeline, dataset_id = 2)\n",
    "ue_mal_dataset = NRTimeDataset(df=malicious_ue, frame_length = frame_size, transform=ue_benign_dataset.transform, dataset_id = 2, fit=False)\n",
    "\n",
    "# Save the fit UE data transform for live data inference later \n",
    "pickle.dump(ue_benign_dataset.transform, open('artifacts/ue_transform.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split the benign data \n",
    "ue_benign_split = torch.utils.data.random_split(ue_benign_dataset, [0.6,0.2,0.2])\n",
    "ue_train_dataset, ue_val_dataset, ue_test_dataset = ue_benign_split\n",
    "\n",
    "# All malicious data goes in the test set - The autoencoder is trained on BENIGN DATA ONLY!\n",
    "ue_test_dataset = ue_mal_dataset + ue_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UE Data Loaders \n",
    "ue_train_dataloader = DataLoader(ue_train_dataset, batch_size=100, shuffle=True)\n",
    "ue_test_dataloader = DataLoader(ue_test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UE Detection Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN filter sizes for the autoencoder encoder and decoder \n",
    "filter_sizes = [8, 4]\n",
    "\n",
    "# Model definition - UE\n",
    "CNNautoencoder_ue = ConvAutoencoder(n_features = ue_benign_dataset.samples.size()[1], filter_sizes=filter_sizes)\n",
    "CNNautoencoder_ue.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Lightning model instantiation - Information about training will be output to the lightning_logs dir\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "NR_Autoencoder_ue = LitTimeAutoencoder(CNNautoencoder_ue, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and save the model \n",
    "# Autoencoder training \n",
    "trainer_ue = L.Trainer(limit_train_batches=100, max_epochs=100, callbacks=[AutoencoderReconstructionLoss()])\n",
    "trainer_ue.fit(model=NR_Autoencoder_ue, train_dataloaders=ue_train_dataloader) # Model is the lightning module here \n",
    "\n",
    "# Save the ue state_dict\n",
    "torch.save(CNNautoencoder_ue.state_dict(), 'artifacts/ue_state_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UE model reconstruction loss \n",
    "trainer_ue.test(NR_Autoencoder_ue, dataloaders=ue_test_dataloader)\n",
    "plot_reconsctruction_loss(NR_Autoencoder_ue.reconstruction_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Statistics \n",
    "Autoencoder-based anomaly detection is based on the difference in reconstruction loss between benign and malicious samples. To determine the difference between anaomalous and benign samples we first must calculate the reconstruction loss statistics of benign samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice Model \n",
    "\n",
    "# Get the mean and std of reconstruction loss for benign and malicious samples \n",
    "slice_benign_loss_list = [loss for loss, label in NR_Autoencoder_slice.reconstruction_loss if label == 0]\n",
    "slice_malicious_loss_list = [loss for loss, label in NR_Autoencoder_slice.reconstruction_loss if label == 1]\n",
    "slice_mean, slice_std = loss_statistics(slice_benign_loss_list)\n",
    "\n",
    "# Calculate an example m-distance based on loss statistics \n",
    "m_dist = sample_distance(slice_benign_loss_list[0], slice_mean, slice_std)\n",
    "print('Slice model statistics: ', slice_mean, slice_std)\n",
    "print('Sample benign m-distance: ', m_dist)\n",
    "\n",
    "slice_threshold_metrics = {'mean': slice_mean, 'std': slice_std}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the anomaly detection threshold based on some number of stds \n",
    "slice_detection_threshold = slice_mean + 3*slice_std\n",
    "\n",
    "# Calculate confusion matrix stats based on the loss statistics \n",
    "n_fp = len([loss for loss in slice_benign_loss_list if loss >= slice_detection_threshold])\n",
    "n_tp = len([loss for loss in slice_malicious_loss_list if loss >= slice_detection_threshold])\n",
    "n_fn = len(slice_malicious_loss_list) - n_tp\n",
    "n_tn = len(slice_benign_loss_list) - n_fp\n",
    "\n",
    "print('True positives: ', n_tp)\n",
    "print('False positives: ', n_fp)\n",
    "print('True negatives: ', n_tn)\n",
    "print('False negatives: ', n_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'size':15}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "total_mal = n_tp + n_fn \n",
    "total_benign = n_fp + n_tn\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(8,16), sharex=True, sharey=True)\n",
    "fig.supxlabel('Predicted Label')\n",
    "fig.supylabel('True Label')\n",
    "fig.suptitle('Slice Attack Detection Confusion Matricies')\n",
    "for n in range(3):\n",
    "    # Set the anomaly detection threshold based on some number of stds \n",
    "    slice_detection_threshold = slice_mean + (n+1)*slice_std\n",
    "\n",
    "    # Calculate confusion matrix stats based on the loss statistics \n",
    "    n_fp = len([loss for loss in slice_benign_loss_list if loss >= slice_detection_threshold])\n",
    "    n_tp = len([loss for loss in slice_malicious_loss_list if loss >= slice_detection_threshold])\n",
    "    n_fn = len(slice_malicious_loss_list) - n_tp\n",
    "    n_tn = len(slice_benign_loss_list) - n_fp\n",
    "\n",
    "    axes[n].set_title('Slice Attack Detection - Mean + {} Std. Detection'.format(n))\n",
    "\n",
    "    # Plot the confusion matrix for visualization \n",
    "    [[n_tp,n_fp],[n_tn,n_fn]]\n",
    "    cm = np.array([[n_tp/total_mal,n_fn/total_mal],[n_fp/total_benign,n_tn/total_benign]])\n",
    "    x_labels = ['Malicious', 'Benign']\n",
    "    y_labels = ['Malicious', 'Benign']\n",
    "    s = seaborn.heatmap(cm, xticklabels=x_labels, yticklabels=y_labels, annot=True, ax=axes[n])\n",
    "    # s.set(xlabel='Slice Predicted Label', ylabel='Slice True Label')\n",
    "    axes[n].set_title(\"Threshold = Mean reconstruction \\n loss + {} Std. Deviation\".format(n+1))\n",
    "\n",
    "figure = s.get_figure()    \n",
    "figure.savefig('plots/Slice_CM_detection_threshold-{}.png'.format(slice_detection_threshold), dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UE model \n",
    "\n",
    "# Get the mean and std of reconstruction loss for benign and malicious samples \n",
    "ue_benign_loss_list = [loss for loss, label in NR_Autoencoder_ue.reconstruction_loss if label == 0]\n",
    "ue_malicious_loss_list = [loss for loss, label in NR_Autoencoder_ue.reconstruction_loss if label == 1]\n",
    "ue_mean, ue_std = loss_statistics(ue_benign_loss_list)\n",
    "ue_mal_mean, ue_mal_std = loss_statistics(ue_malicious_loss_list)\n",
    "\n",
    "# Calculate an example m-distance based on loss statistics \n",
    "m_dist = sample_distance(ue_malicious_loss_list[0], ue_mean, ue_std)\n",
    "print('UE model statistics: ', ue_mean, ue_std, m_dist)\n",
    "print('UE malicious statistics: ', ue_mal_mean, ue_mal_std)\n",
    "\n",
    "ue_threshold_metrics = {'mean': ue_mean, 'std': ue_std}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the anomaly detection threshold based on some number of stds \n",
    "\n",
    "# For UE detection we want to set a high threshold - It is bad to ban a legitimate user so we should only treat the most anomalous\n",
    "# samples as malicious\n",
    "ue_detection_threshold = ue_mean + 3*ue_std\n",
    "\n",
    "# TP, FP, TN, FN stats using reconstruction loss as a threshold metric \n",
    "n_fp = len([loss for loss in ue_benign_loss_list if loss >= ue_detection_threshold])\n",
    "n_tp = len([loss for loss in ue_malicious_loss_list if loss >= ue_detection_threshold])\n",
    "n_fn = len(ue_malicious_loss_list) - n_tp\n",
    "n_tn = len(ue_benign_loss_list) - n_fp\n",
    "\n",
    "print('True positives: ', n_tp)\n",
    "print('False positives: ', n_fp)\n",
    "print('True negatives: ', n_tn)\n",
    "print('False negatives: ', n_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix for visualization \n",
    "[[n_tp,n_fp],[n_tn,n_fn]]\n",
    "cm = np.array([[n_tp,n_fn],[n_fp,n_tn]])\n",
    "x_labels = ['Malicious', 'Benign']\n",
    "y_labels = ['Malicious', 'Benign']\n",
    "s = seaborn.heatmap(cm, xticklabels=x_labels, yticklabels=y_labels, annot=True)\n",
    "s.set(xlabel='UE Predicted Label', ylabel='UE True Label')\n",
    "plt.title(\"UE Attack Detection - Mean + 3 Std. Detection\")\n",
    "\n",
    "figure = s.get_figure()    \n",
    "figure.savefig('plots/UE_CM_detection_threshold-{}.png'.format(ue_detection_threshold), dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'size':15}\n",
    "\n",
    "total_mal = n_tp + n_fn \n",
    "total_benign = n_fp + n_tn\n",
    "\n",
    "plt.rc('font', **font)\n",
    "fig, axes = plt.subplots(3, 1, figsize=(8,16), sharex=True, sharey=True)\n",
    "fig.supxlabel('Predicted Label')\n",
    "fig.supylabel('True Label')\n",
    "fig.suptitle('UE Attack Detection Confusion Matricies')\n",
    "for n in range(3):\n",
    "    # Set the anomaly detection threshold based on some number of stds \n",
    "    ue_detection_threshold = ue_mean + (n+1)*ue_std\n",
    "\n",
    "    # TP, FP, TN, FN stats using reconstruction loss as a threshold metric \n",
    "    n_fp = len([loss for loss in ue_benign_loss_list if loss >= ue_detection_threshold])\n",
    "    n_tp = len([loss for loss in ue_malicious_loss_list if loss >= ue_detection_threshold])\n",
    "    n_fn = len(ue_malicious_loss_list) - n_tp\n",
    "    n_tn = len(ue_benign_loss_list) - n_fp\n",
    "\n",
    "    # Plot the confusion matrix for visualization \n",
    "    [[n_tp,n_fp],[n_tn,n_fn]]\n",
    "    cm = np.array([[n_tp/total_mal,n_fn/total_mal],[n_fp/total_benign,n_tn/total_benign]])\n",
    "    x_labels = ['Malicious', 'Benign']\n",
    "    y_labels = ['Malicious', 'Benign']\n",
    "    s = seaborn.heatmap(cm, xticklabels=x_labels, yticklabels=y_labels, annot=True, ax=axes[n])\n",
    "    # s.set(xlabel='UE Predicted Label', ylabel='UE True Label')\n",
    "    axes[n].set_title(\"Threshold = Mean reconstruction \\n loss + {} Std. Deviation\".format(n+1))\n",
    "\n",
    "\n",
    "figure = s.get_figure()    \n",
    "figure.savefig('plots/UE_CM_detection_threshold-{}.png'.format(ue_detection_threshold), dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the detection parameters to the artifacts folder \n",
    "pickle.dump(slice_threshold_metrics, open('artifacts/slice_threshold_metrics.pkl', 'wb'))\n",
    "pickle.dump(ue_threshold_metrics, open('artifacts/ue_threshold_metrics.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "5G",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
